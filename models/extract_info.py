import os
import base64
from typing import Optional
from pydantic import BaseModel, Field
from dotenv import load_dotenv

from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI

# Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# ----------------- Khai b√°o schema th√¥ng tin ƒë·ªì u·ªëng ----------------- #
class ExtractedDrinkInfo(BaseModel):
    drink_type: Optional[str] = Field(
        default=None, description="Lo·∫°i ƒë·ªì u·ªëng (V√≠ d·ª•: Coffee, Tr√†, Capuchino,...)"
    )
    drink_color: Optional[str] = Field(
        default=None, description="M√†u s·∫Øc c·ªßa ƒë·ªì u·ªëng "
    )
    container_type: Optional[str] = Field(
        default=None, description="Lo·∫°i v√† h√¨nh d√°ng c·ªßa c·ªëc ho·∫∑c ly "
    )
    ingredients: Optional[str] = Field(
        default=None, description="Th√†nh ph·∫ßn ch√≠nh "
    )
    topping: Optional[str] = Field(
        default=None, description="L·ªõp ph·ªß tr√™n ƒë·ªì u·ªëng ."
    )
    suitable_for: Optional[str] = Field(
        default=None, description="ƒê·ªëi t∆∞·ª£ng ho·∫∑c ho√†n c·∫£nh th∆∞·ªüng th·ª©c l√Ω t∆∞·ªüng"
    )

class LLMExtract:
    @staticmethod 
    def image_to_base64(image_path: str) -> str:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    # ----------------- H√†m m√¥ t·∫£ th√¥ng tin ƒë·ªì u·ªëng ----------------- #
    def llm_extract(*, encoded_image: Optional[str] = None, url: Optional[str] = None) -> Optional[ExtractedDrinkInfo]:
        if encoded_image is None and url is None:
            print("Image is None.")
            return None

        parser = JsonOutputParser(pydantic_object=ExtractedDrinkInfo)

        # T·∫°o dict h√¨nh ·∫£nh
        image_dict = {"url": url} if url else {"url": f"data:image/jpeg;base64,{encoded_image}"}

        # Prompt ti·∫øng Vi·ªát y√™u c·∫ßu m√¥ t·∫£ ƒë·ªì u·ªëng
        prompt = [
            AIMessage(
                content=(
                    "B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh, chuy√™n tr√≠ch xu·∫•t th√¥ng tin c√≥ c·∫•u tr√∫c t·ª´ ·∫£nh ƒë·ªì u·ªëng.\n\n"
                    "Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch k·ªπ ·∫£nh ƒë·ªì u·ªëng t√¥i cung c·∫•p v√† tr√≠ch xu·∫•t c√°c th√¥ng tin sau:\n"
                    "1. **drink_type**: T√™n lo·∫°i ƒë·ªì u·ªëng ‚Äì vi·∫øt b·∫±ng **ti·∫øng Anh v√† ti·∫øng Vi·ªát**\n"
                    "2. **drink_color**: M√†u s·∫Øc c·ªßa ƒë·ªì u·ªëng(m√¥ t·∫£ chi ti·∫øt m√†u s·∫Øc)\n"
                    "3. **container_type**: H√¨nh d√°ng v√† ki·ªÉu d√°ng c·ªßa c·ªëc ho·∫∑c ly(V√≠ d·ª•: c·ªëc nh·ª±a, c·ªëc th·ªßy tinh,...)\n"
                    "4. **ingredients**: Th√†nh ph·∫ßn ch√≠nh(V√≠ d·ª•: s·ªØa, ƒë∆∞·ªùng, tr√¢n ch√¢u, ƒë√°,...)\n"
                    "5. **topping**: L·ªõp ph·ªß n·∫øu c√≥(V√≠ d·ª•: kem b√©o, tr√¢n ch√¢u, th·∫°ch,...). N·∫øu kh√¥ng c√≥ l·ªõp ph·ªß tr·∫£ v·ªÅ None.\n"
                    "6. **suitable_for**: ƒê·ªëi t∆∞·ª£ng ho·∫∑c ho√†n c·∫£nh th∆∞·ªüng th·ª©c l√Ω t∆∞·ªüng\n\n"
                    "üëâ Y√™u c·∫ßu:\n"
                    "- T·∫•t c·∫£ th√¥ng tin ph·∫£i ƒë∆∞·ª£c vi·∫øt b·∫±ng **ti·∫øng Vi·ªát**, ngo·∫°i tr·ª´ `drink_type` l√† ti·∫øng Anh k√®m ti·∫øng Vi·ªát.\n"
                    "- N·∫øu kh√¥ng c√≥ th√¥ng tin, h√£y ghi r√µ `kh√¥ng c√≥ topping`.\n"
                    "- Tr·∫£ l·ªùi ƒë√∫ng theo ƒë·ªãnh d·∫°ng JSON sau:\n"
                    f"{parser.get_format_instructions()}\n"
                    "Ch·ªâ tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON, kh√¥ng k√®m gi·∫£i th√≠ch."
                )
            ),
            HumanMessage(
                content=[
                    {"type": "text", "text": "Tr√≠ch xu·∫•t th√¥ng tin ƒë·ªì u·ªëng trong ·∫£nh n√†y."},
                    {"type": "image_url", "image_url": image_dict}
                ]
            ),
        ]

        # L·∫•y API key t·ª´ .env
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("GOOGLE_API_KEY is not set.Check .env file.")
            return None

        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash-latest",
            temperature=0.7,
            google_api_key=api_key
        )

        # G·ªçi m√¥ h√¨nh
        try:
            response = llm.invoke(prompt)
            data = parser.parse(response.content)
            return ExtractedDrinkInfo(**data)
        except Exception as e:
            print(f"Error response from model: {e}")
            return None
